"""
æŠ–éŸ³çƒ­æ¦œæŠ“å–å¹¶æ¨é€åˆ°é£ä¹¦ç¾¤
ä¸»ç¨‹åºå…¥å£
"""
import os
import time
import logging
import schedule
from datetime import datetime
from dotenv import load_dotenv

from douyin_scraper import DouyinScraper
from feishu_notifier import FeishuNotifier


# é…ç½®æ—¥å¿—
def setup_logger():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    log_level = os.getenv('LOG_LEVEL', 'INFO')
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('douyin_hot_scraper.log', encoding='utf-8')
        ]
    )


logger = logging.getLogger(__name__)


def scrape_and_send():
    """æŠ“å–æŠ–éŸ³çƒ­æ¦œå¹¶å‘é€åˆ°é£ä¹¦ç¾¤"""
    try:
        logger.info("=" * 50)
        logger.info("å¼€å§‹æ‰§è¡Œçƒ­æ¦œæŠ“å–ä»»åŠ¡")

        # è·å–ç¯å¢ƒå˜é‡
        webhook_url = os.getenv('FEISHU_WEBHOOK_URL')
        if not webhook_url:
            logger.error("æœªé…ç½® FEISHU_WEBHOOK_URLï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
            return

        # åˆ›å»ºæŠ“å–å™¨å’Œé€šçŸ¥å™¨
        scraper = DouyinScraper()
        notifier = FeishuNotifier(webhook_url)

        # æŠ“å–çƒ­æ¦œ
        hot_list = scraper.fetch_hot_list(limit=20)

        if not hot_list:
            logger.error("æœªèƒ½è·å–çƒ­æ¦œæ•°æ®")
            # å‘é€é”™è¯¯é€šçŸ¥
            notifier.send_text_message("âš ï¸ æŠ–éŸ³çƒ­æ¦œæŠ“å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
            return

        # å‘é€åˆ°é£ä¹¦
        # ä¼˜å…ˆä½¿ç”¨äº¤äº’å¼å¡ç‰‡ï¼Œå¤±è´¥åˆ™ä½¿ç”¨æ–‡æœ¬æ¶ˆæ¯
        success = notifier.send_interactive_message(hot_list)

        if not success:
            logger.warning("äº¤äº’å¼å¡ç‰‡å‘é€å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨æ–‡æœ¬æ¶ˆæ¯")
            text_content = scraper.format_hot_list_text(hot_list)
            success = notifier.send_text_message(text_content)

        if success:
            logger.info("çƒ­æ¦œæ•°æ®å‘é€æˆåŠŸ")
        else:
            logger.error("çƒ­æ¦œæ•°æ®å‘é€å¤±è´¥")

        logger.info("çƒ­æ¦œæŠ“å–ä»»åŠ¡å®Œæˆ")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"æ‰§è¡Œä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)


def main():
    """ä¸»å‡½æ•°"""
    # åŠ è½½ç¯å¢ƒå˜é‡
    load_dotenv()

    # é…ç½®æ—¥å¿—
    setup_logger()

    logger.info("ğŸš€ æŠ–éŸ³çƒ­æ¦œæŠ“å–æœåŠ¡å¯åŠ¨")

    # è·å–é…ç½®
    interval_hours = int(os.getenv('SCRAPE_INTERVAL_HOURS', '1'))
    webhook_url = os.getenv('FEISHU_WEBHOOK_URL')

    # éªŒè¯é…ç½®
    if not webhook_url:
        logger.error("âŒ æœªé…ç½® FEISHU_WEBHOOK_URL")
        logger.error("è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥ä½ çš„é£ä¹¦ Webhook URL")
        return

    logger.info(f"âš™ï¸  é…ç½®ä¿¡æ¯:")
    logger.info(f"   - æŠ“å–é—´éš”: æ¯ {interval_hours} å°æ—¶")
    logger.info(f"   - Webhook: {webhook_url[:50]}...")

    # ç«‹å³æ‰§è¡Œä¸€æ¬¡
    logger.info("ğŸ”„ ç«‹å³æ‰§è¡Œé¦–æ¬¡æŠ“å–...")
    scrape_and_send()

    # è®¾ç½®å®šæ—¶ä»»åŠ¡
    logger.info(f"â° è®¾ç½®å®šæ—¶ä»»åŠ¡: æ¯ {interval_hours} å°æ—¶æ‰§è¡Œä¸€æ¬¡")
    schedule.every(interval_hours).hours.do(scrape_and_send)

    # å¾ªç¯æ‰§è¡Œ
    logger.info("âœ… æœåŠ¡è¿è¡Œä¸­ï¼ŒæŒ‰ Ctrl+C é€€å‡º")

    try:
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡å¾…æ‰§è¡Œçš„ä»»åŠ¡
    except KeyboardInterrupt:
        logger.info("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")


if __name__ == "__main__":
    main()
